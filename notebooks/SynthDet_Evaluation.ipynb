{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SynthDet Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the model prediction visualization. You can load your model and visualize predicted bounding boxes for the GroceriesReal validation dataset. This notebook would show you the performance metrics (mAP, mAP@IOU50, mAR@100) for your model based on GroceriesReal test dataset. Also, this notebook can analyze the easy and hard cases from the point of view of the model. This would provide a better understanding about how to minimize sim2real gaps or improve model performance.<br>\n",
    "You can use this notebook by the following steps:\n",
    "- Specify the model path. Then, the notebook would load the checkpoints into a `FasterRCNN` estimator. The `FasterRCNN` can provide model predictions.\n",
    "- Provide the model performance metrics.\n",
    "- Can either specify or randomly select some cases for the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "Specify your settings down below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local data path to save downloaded dataset:\n",
    "# Why do we need this setting?\n",
    "\n",
    "# switch to this default path to allow user running inside docker container\n",
    "# data_root = \"/data\"\n",
    "data_root = \"/Users/bowen.li/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a pre-trained model that can be used to calculate model performance as well as prediction visualization. You can use one of the model that we pre-trained or use the model that you have trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Real-trained estimator on 760 images\n",
    "# estimator_url = \"https://storage.googleapis.com/datasetinsights/models/Real-World/FasterRCNN.estimator\"\n",
    "\n",
    "# 2. Synth-trained estimator on 400K SynthDet dataset\n",
    "# estimator_url = \"https://storage.googleapis.com/datasetinsights/models/Synthetic/FasterRCNN.estimator\"\n",
    "\n",
    "# 3. Fine-tuned estimator (pre-trained on 400K Synthetic data and fine-tuned on 76 images)\n",
    "# estimator_url = \"https://storage.googleapis.com/datasetinsights/models/Synthetic-And-Real-World-76-images/FasterRCNN.estimator\"\n",
    "\n",
    "# 4. Fine-tuned estimator (pre-trained on 400K Synthetic data and fine-tuned on 380 images)\n",
    "# estimator_url = \"https://storage.googleapis.com/datasetinsights/models/Synthetic-And-Real-World-380-images/FasterRCNN.estimator\"\n",
    "\n",
    "# 5. Fine-tuned estimator (pre-trained on 400K Synthetic data and fine-tuned on 760 images)\n",
    "# This is the estimator that provide the best result.\n",
    "estimator_url = \"https://storage.googleapis.com/datasetinsights/models/Synthetic-And-Real-World-760-images/FasterRCNN.estimator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to download the model that they have stored on GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GroceriesReal Dataset\n",
    "Download GrocereisReal data. You only need to download the data once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You only need to download the data once.\n",
    "# change this variable once we have public groceries real dataset name\n",
    "import os\n",
    "from datasetinsights.io import create_downloader\n",
    "\n",
    "data_path = os.path.join(data_root, \"groceries\", \"v3\")\n",
    "\n",
    "def download_dataset():\n",
    "    groceries_real_source_uri = \"https://storage.googleapis.com/datasetinsights/data/groceries/v3.zip\"\n",
    "    downloader = create_downloader(source_uri=groceries_real_source_uri)\n",
    "    downloader.download(source_uri=groceries_real_source_uri, output=data_path, include_binary=True)\n",
    "\n",
    "# uncomment this\n",
    "# download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from yacs.config import CfgNode as CN\n",
    "from datasetinsights.estimators import create_estimator\n",
    "\n",
    "def estimator_config():\n",
    "    config_yaml = \"\"\"\n",
    "        estimator: FasterRCNN\n",
    "        backbone: resnet50\n",
    "        num_classes: 64\n",
    "        task: object_detection\n",
    "        test:\n",
    "          batch_size: 8\n",
    "          dataset:\n",
    "            name: GroceriesReal\n",
    "            args:\n",
    "              version: v3\n",
    "              split: test\n",
    "        metrics:\n",
    "          mAP:\n",
    "            name: MeanAveragePrecisionAverageOverIOU\n",
    "          mAPIOU50:\n",
    "            name: MeanAveragePrecisionIOU50\n",
    "          mAR:\n",
    "            name: MeanAverageRecallAverageOverIOU\n",
    "        pretrained: False\n",
    "        pretrained_backbone: True\n",
    "        synchronize_metrics: True\n",
    "    \"\"\"\n",
    "    config = CN.load_cfg(config_yaml)\n",
    "    \n",
    "    return config\n",
    "\n",
    "def load_estimator(checkpoint_file):  \n",
    "    config = estimator_config()\n",
    "\n",
    "    estimator = create_estimator(\n",
    "        name=config.estimator,\n",
    "        config=config,\n",
    "        checkpoint_dir = tempfile.TemporaryDirectory().name,\n",
    "        checkpoint_file=checkpoint_file,\n",
    "        kfp_metrics_dir = tempfile.TemporaryDirectory().name,\n",
    "    )\n",
    "\n",
    "    return estimator\n",
    "\n",
    "estimator = load_estimator(estimator_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance metrics\n",
    "This section would show you the model performance on GroceriesReal test dataset. You would see:\n",
    "\n",
    "We report three evaluation metrics that's commonly used for object detection task\n",
    "- [mAP](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.evaluation_metrics.html#datasetinsights.evaluation_metrics.average_precision_2d.MeanAveragePrecisionAverageOverIOU): Average Precision average over all labels and IOU thresholds = 0.5:0.95:0.05\n",
    "- [mAPIOU50](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.evaluation_metrics.html#datasetinsights.evaluation_metrics.average_precision_2d.MeanAveragePrecisionIOU50): Mean Average Precision at IOU=50%.\n",
    "- [mAR](https://datasetinsights.readthedocs.io/en/latest/datasetinsights.evaluation_metrics.html#datasetinsights.evaluation_metrics.average_recall_2d.MeanAverageRecallAverageOverIOU): Average Recall average over all labels and IOU thresholds = 0.5:0.95:0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will take a while (1 hour) if you run it locally as it will go through the whole test dataset and make predictions.\n",
    "# It will be rougly 3-5 min on GPU...\n",
    "estimator.model.eval()\n",
    "estimator.evaluate(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mAP</td>\n",
       "      <td>0.703276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mAPIOU50</td>\n",
       "      <td>0.914774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mAR</td>\n",
       "      <td>0.752249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric_name  metric_value\n",
       "0         mAP      0.703276\n",
       "1    mAPIOU50      0.914774\n",
       "2         mAR      0.752249"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = estimator.metrics\n",
    "df = pd.DataFrame({\n",
    "    \"metric_name\": [\"mAP\", \"mAPIOU50\", \"mAR\"],\n",
    "    \"metric_value\": [\n",
    "        metrics[\"mAP\"].compute(), \n",
    "        metrics[\"mAPIOU50\"].compute(), \n",
    "        metrics[\"mAR\"].compute()\n",
    "    ]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the loaded model to predict on GroceriesReal Validation Dataset. We highlight predicted bounding boxes into 2 colors:\n",
    "- <font color='green'>Green boxes</font>: it's a correct predicted label and overlap the true box enough (overlap >= 0.5). <br>\n",
    "- <font color='red'>Red boxes</font>: it's a wrong prediction.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetinsights.datasets import Dataset\n",
    "test_dataset = Dataset.create(\n",
    "    \"GroceriesReal\",\n",
    "    data_path=data_path,\n",
    "    split=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetinsights.stats.visualization.plots import match_boxes, plot_bboxes\n",
    "from datasetinsights.stats import grid_plot\n",
    "def visualize_predictions(estimator, dataset, index):\n",
    "    # keep in notebook\n",
    "    pil_image, gt_bboxes = dataset[index]\n",
    "    pred_bboxes = estimator.predict(pil_image, box_score_thresh=0.5)\n",
    "    colors = match_boxes(pred_bboxes, gt_bboxes)\n",
    "    gt_plot = plot_bboxes(pil_image, gt_bboxes, dataset.label_mappings)\n",
    "    pred_plot = plot_bboxes(pil_image, pred_bboxes, dataset.label_mappings, colors)\n",
    "    \n",
    "    titles = [\n",
    "        f\"ground truth for Image {index + 1}\",\n",
    "        f\"model prediction for Image {index + 1}\",\n",
    "    ]\n",
    "    grid_plot([[gt_plot, pred_plot]], figsize=(7, 10), img_type=\"rgb\", titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions for some user-selected or randomly-selected cases** <br>\n",
    "You can specify some cases or randomly select K cases. For each image, there are two plots:\n",
    "- The left one is the ground truth image. <br>\n",
    "- The right one is the model prediction.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6fcec044af35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# image_indicies = [0, 1, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# specify image_indicies if you want to visualize a particular set of images\n",
    "# image_indicies = [0, 1, 2]\n",
    "K = 3\n",
    "image_indicies = sorted(random.randint(0, len(test_dataset) - 1, size=K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index in image_indicies:\n",
    "    visualize_predictions(estimator, test_dataset, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
