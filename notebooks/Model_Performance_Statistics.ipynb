{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Statistics\n",
    "This example notebook shows statistics, including box plots, mean and variance, for model performance. You can run an experimnet multiple times and use this notebook to analyze the metrics results distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Model Performance\n",
    "You can train models multiple times (say 10 times) using the same Synthetic data. And copy model performances down below. For each metric, you can copy metric value into a list (Each column represents metric value for one run).\n",
    "1. In the baseline performance session, copy the baseline model performance.\n",
    "2. In the new performance session, copy the model you want to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline and New Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {0: \"base mAP\", 1: \"new mAP\", 2: \"base mAP50\", 3: \"new mAP50\", 4: \"base mAR\", 5: \"new mAR\"}\n",
    "def collection(mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new):\n",
    "    performance = pd.DataFrame()\n",
    "    mAP_base = pd.Series(mean_ap_base)\n",
    "    mAP50_base = pd.Series(mean_ap_50_base)\n",
    "    mAR_base = pd.Series(mean_ar_base)\n",
    "    mAP_new = pd.Series(mean_ap_new)\n",
    "    mAP50_new = pd.Series(mean_ap_50_new)\n",
    "    mAR_new = pd.Series(mean_ar_new)\n",
    "    performance = performance.append(mAP_base.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.append(mAP_new.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.append(mAP50_base.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.append(mAP50_new.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.append(mAR_base.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.append(mAR_new.describe()[1:3],ignore_index=True)\n",
    "    performance = performance.rename(index=indices)\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P value\n",
    "# A p-value is the probability that the results from your sample data occurred by chance. \n",
    "# P-values are from 0 to 1. Low p-values are good; They indicate your data did not occur by chance. \n",
    "# In most cases, a p-value of 0.05 is accepted to mean the data is valid.\n",
    "\n",
    "def p_value_calculation(mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new):\n",
    "    t2, p_value = stats.ttest_ind(mean_ap_base, mean_ap_new)\n",
    "    print(\"mAP:\")\n",
    "    print(f\"p_value = {p_value: .4f}\")\n",
    "    t2, p_value = stats.ttest_ind(mean_ap_50_base, mean_ap_50_new)\n",
    "    print(\"mAP@IOU50:\")\n",
    "    print(f\"p_value = {p_value: .4f}\")\n",
    "    t2, p_value = stats.ttest_ind(mean_ar_base, mean_ar_new)\n",
    "    print(\"mAR:\")\n",
    "    print(f\"p_value = {p_value: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"performance\", \"metrics_type\"]\n",
    "def performance_plot(title,mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new, y_range=[0, 0.5]):\n",
    "    names = list(indices.values())\n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=title)))\n",
    "    fig.update_yaxes(range=y_range)\n",
    "    fig.add_trace(go.Box(y=mean_ap_base, name=names[0], marker_color = 'indianred'))\n",
    "    fig.add_trace(go.Box(y=mean_ap_new, name=names[1], marker_color = 'lightseagreen'))\n",
    "    fig.add_trace(go.Box(y=mean_ap_50_base, name=names[2], marker_color = 'indianred'))\n",
    "    fig.add_trace(go.Box(y=mean_ap_50_new, name=names[3], marker_color = 'lightseagreen'))\n",
    "    fig.add_trace(go.Box(y=mean_ar_base, name=names[4], marker_color = 'indianred'))\n",
    "    fig.add_trace(go.Box(y=mean_ar_new, name=names[5], marker_color = 'lightseagreen'))\n",
    "    return fig\n",
    "\n",
    "def single_performance_plot(title, mean_ap, mean_ap_50, mean_ar, y_range=[0.5, 1.0]):\n",
    "    fig = go.Figure(layout=go.Layout(title=go.layout.Title(text=title)))\n",
    "    fig.update_yaxes(range=y_range)\n",
    "    fig.add_trace(go.Box(y=mean_ap, name=\"mAP\", marker_color = 'indianred'))\n",
    "    fig.add_trace(go.Box(y=mean_ap_50, name=\"mAP@IOU50\", marker_color = 'indianred'))\n",
    "    fig.add_trace(go.Box(y=mean_ar, name=\"mAR\", marker_color = 'indianred'))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve(perf):\n",
    "    i1 = (perf[\"mean\"][1] - perf[\"mean\"][0]) / perf[\"mean\"][0]\n",
    "    i2 = (perf[\"mean\"][3] - perf[\"mean\"][2]) / perf[\"mean\"][2]\n",
    "    i3 = (perf[\"mean\"][5] - perf[\"mean\"][4]) / perf[\"mean\"][4]\n",
    "    improve_value = (i1 + i2 + i3) / 3\n",
    "    print(f\"The model performance based on new dataset improved by {improve_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline performance\n",
    "base_dataset_name = \"vje7zGM\"\n",
    "mean_ap_base = [0.025,0.016,0.011,0.015,0.020,0.032,0.046,0.019,0.013,0.028]\n",
    "mean_ap_50_base = [0.052,0.033,0.023,0.031,0.046,0.079,0.118,0.044,0.032,0.082]\n",
    "mean_ar_base = [0.077,0.070,0.038,0.048,0.086,0.114,0.192,0.072,0.059,0.113]\n",
    "\n",
    "# new performance\n",
    "new_dataset_name = \"GNXBzQ0\"\n",
    "mean_ap_new = [0.035,0.037,0.055,0.060,0.069,0.109,0.055,0.069,0.050,0.090]\n",
    "mean_ap_50_new = [0.074,0.079,0.126,0.138,0.174,0.307,0.117,0.162,0.097,0.234]\n",
    "mean_ar_new = [0.113,0.095,0.139,0.167,0.164,0.303,0.140,0.199,0.164,0.217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "performance = collection(mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = performance_plot(f\"Baseline ({base_dataset_name}) vs New ({new_dataset_name}) dataset\", mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p_value_calculation(mean_ap_base, mean_ap_50_base, mean_ar_base, mean_ap_new, mean_ap_50_new, mean_ar_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
